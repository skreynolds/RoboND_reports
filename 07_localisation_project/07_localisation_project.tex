\documentclass[a4paper]{article}

%------------------------------------------------------------
\usepackage[a4paper, total={6in, 9in}]{geometry}
\usepackage{algorithm}
\usepackage[noend]{algpseudocode}
\usepackage{amsmath}
\usepackage{amsfonts}
\usepackage{booktabs}
\usepackage{caption}
\usepackage{enumitem}
\usepackage{graphicx}
\usepackage{float}
\usepackage{inconsolata}
\usepackage{listings}
\usepackage{pstricks-add}
\usepackage{siunitx}
\usepackage[most]{tcolorbox}
\usepackage{tikz}
\usepackage{epstopdf} %converting to PDF
\usepackage{hyperref}

\usetikzlibrary{shapes.geometric}

%------------------------------------------------------------
\graphicspath{{./fig/}}

%------------------------------------------------------------
\setlength{\parindent}{0in}

\lstdefinestyle{Python}{
	language        = Python,
	basicstyle      = \ttfamily,
	keywordstyle    = \color{blue},
	keywordstyle    = [2] \color{teal}, % just to check that it works
	stringstyle     = \color{green},
	commentstyle    = \color{red}\ttfamily
}

%------------------------------------------------------------
\newtcblisting[auto counter]{sexylisting}[2][]{sharp corners, 
    fonttitle=\bfseries, colframe=gray, listing only, 
    listing options={basicstyle=\ttfamily,language=Python}, 
    title=Listing \thetcbcounter: #2, #1}

%------------------------------------------------------------
\tikzstyle{block} = [draw, fill=blue!20, rectangle, 
    minimum height=3em, minimum width=3em]
\tikzstyle{sum} = [draw, fill=blue!20, circle, node distance=1cm]
\tikzstyle{input} = [coordinate]
\tikzstyle{output} = [coordinate]
\tikzstyle{pinstyle} = [pin edge={to-,thin,black}]

%------------------------------------------------------------

\begin{document}
\title{Localisation: Where Am I?}
\author{Shane Reynolds}
\maketitle
\tableofcontents
\newpage
\section{Introduction}
Suppose a robot has an unknown pose in an environment for which it has a map. The robot takes sensor readings, and based on these observations, must infer a set of poses where it could be located in the environment. In robotics, this scenario is known as the \textit{localisation problem} \cite{Cox:1991, Wang:1988}. In simpler terms, localisation is the problem of estimating a mobile robot's location and orientation relative to its environment, given sensor data \cite{Thrun:2001}. This is not as straight forward as it appears given robot actuators are subject to small random perturbations in performance, and sensors provide imperfect measurement. Compounding these problems is the fact that the robot may not even know it's initial pose relative to the environment. This paper explores two approaches to solving the localisation problem, after providing a brief discussion on the common variations of the problem. The first of these solutions is the Extended Kalman Filter (EKF): an adaptation of the Kalman Filter, suited to the estimation of non-linear system responses. The second solution is a particle filter method called Monte Carlo Localisation (MCL). The paper concludes with an application of MCL in a Gazebo simulation using an off-the-shelf MCL package in ROS. The MCL implementation is trialled across two different robot models providing opportunities for discussion of implementation robustness, and an analysis of parameter tuning for reliable performance.

\section{Background}
The mobile robot localisation problem comes in three flavours. The simplest involves tracking the robot's pose relative to its environment - called \textit{position tracking}. This scenario requires an initial known estimate of the robot's pose relative to the environment. Robot actions require pose updates using noisey sensor data \cite{Thrun:1999}. Often initial pose estimates are unavailable - this scenario represents a more meaningful problem version called the \textit{global localisation problem}. The goal here is for the robot determine it's pose from scratch, given it is unaware of the initial pose. Finally, the most challenging problem type is referred to as the \textit{kidnapped robot problem} which sees a localised robot tele-ported to another location on the map without knowledge of the move. This is different to the \textit{global localisation problem} scenario because, after tele-porting, the robot incorrectly believes it is somewhere other than its current location. This final scenario is used to test whether a localisation algorithm can recover from a catastrophic failure.

\subsection{Kalman Filters}
Kalman Filters can be used to solve the simplest localisation problem: position tracking. In an ideal world, position tracking is a trivial task in which the robot knows it's starting location, and updates position with perfect actuation and perfect sensor readings. In the real world, however, this is not the case. Actuation is not perfect, and is subject to minor perturbations, or wheel slippage can occur. Furthermore, sensor readings are noisey. The implications are that both movement and measurement are imprecise and subject to stochastic errors. Consider the a mobile robot moving along a one dimensional trajectory. Let the discrete time position be $x_j$, at time $j$. We note that the position at time $j$ is dependent on the previous position at time $j-1$, denoted as $x_{j-1}$, plus any movement action taken by the robot, denoted as $u_j$. Additionally, as previously noted, the robot's actuators are not perfect and are subject to noise, $\omega_j$. We can write $x_j$ as follows:
\begin{equation}
x_j = a x_j + b u_j + \omega_j
\end{equation}

This description is sometimes easier to understand when visualised as a computational block diagram, shown in Figure 1.
\begin{figure}[h]
\centering
\input{./tikzpics/kf_1}
\caption{text}
\end{figure}

Almost always random phenomena are hidden from the observer behind a dynamical system - Kalman described this as follows:\\

\textit{A random function of time may be thought of as the output of a dynamic system excited by an independent Gaussian random process.} \cite{Kalman:1960}\\

This is true for robotic motion, given that we can only attempt to estimate the robot's stochastically perturbed motion, through the use of sensors like odometry, or laser range finders, which are subject to stochastic noise. Letting the measurement of signal $x_j$ be represented by $z_j$, we can write the following equation defining the measurement of $x_j$, subject to noise $\nu_j$, as:
\begin{equation}
z_j = h x_j + \nu_j
\end{equation} 

Equation (2) can be represented in a computational graph as follows:
\begin{figure}[h]
\centering
\input{./tikzpics/kf_2}
\caption{text}
\end{figure}

The fundamental problem that the Kalman Filter tries to answer is: how can an accurate estimate of a hidden stochastic signal be found when it is observed as the output of a dynamical system? The first step to answering this is to create a mathematical model of the system we can use to find an estimate of the measurement, $z_j$, which we call $\hat{z_j}$. This estimate is based on an estimation of the hidden variable, which we denote with $\hat{x}^-_j$. The mathematical model that provides these estimates does not factor in stochasticity seen in actual signals $x_j$ and $z_j$. This is the \textit{a priori} estimate of $x_j$, and is mathematically described as:
\begin{equation}
\hat{x}^-_j = a \hat{x}_{j-1} + b u_j
\end{equation}

The \textit{a priori} estimate is used to predict an output estimate,  $\hat{z}_j$. In turn, $\hat{z}_j$, is used to estimate the difference between predicted signal and the observed signal, referred to as the residual:
\begin{equation}
z_j - \hat{z}_j = z_j - h \hat{x}^-_j
\end{equation}

If the residual is small, then our estimate is good. If it is large then our estimate is not good. We can use the residual in (4) to update our \textit{a priori} estimate, $\hat{x}^-_j$:
\begin{equation}
\hat{x}_j = \hat{x}^-_j + k (z_j - h \hat{x}^-_j)
\end{equation}

A visualisation of the computational architecture for the process can be seen in Figure 3. This is a useful picture as it allows us to see the Kalman filter process decomposed into two distinct phases:
\begin{enumerate}
\item the state prediction phase in which the residual is used to update the \textit{a priori} providing a state prediction, known as the \textit{posterior belief}
\item the measurement update phase in which the \textit{posterior belief} is updated with control actions $u_j$ and used as the new \textit{a priori}, which is combined with sensor readings to compute the new residual.
\end{enumerate}, 
\begin{figure}[h]
\centering
\input{./tikzpics/kf_3}
\caption{text}
\end{figure}

The task of determining $k$, used to refine our estimate, is at the heart of the Kalman filtering process. This is not a trivial task. Further, our problem is complicated when considering robotic motion in multiple dimensions - so far, estimation has only been considered for a 1D problem. Most mobile robots move in 2D, and we may also want to estimate other important locomotion variables such as velocity. Suppose that state was now represented as vector of variables such as position in 2D, including velocity. We define this using bold typeface $\mathbf{x}_j$. Similarly, control actions are represented as $\mathbf{u}_j$, and the measurement for each state variable in $\mathbf{x}_j$ is represented by $\mathbf{z}_j$. Without loss of generality equation (1) becomes:
\begin{equation}
\mathbf{x}_j = \mathbf{A} \mathbf{x}_j + \mathbf{B} \mathbf{u}_j + \boldsymbol{\omega}_j
\end{equation}

Similarly, equation (2) becomes:
\begin{equation}
\mathbf{z}_j = \mathbf{H} \mathbf{x}_j + \boldsymbol{\nu}_j
\end{equation}

The \textit{a priori} estimate of the state variable, shown in equation (3), in multidimensional form, is given by:
\begin{equation}
\hat{\mathbf{x}}^-_j = \mathbf{A} \hat{\mathbf{x}}_j + \mathbf{B} \mathbf{u}_j
\end{equation}

The \textit{a priori} update, shown in equation (5) is given by:
\begin{equation}
\hat{\mathbf{x}}_j = \hat{\mathbf{x}}^-_j + \mathbf{K}_j (\mathbf{z}_j - \mathbf{H} \hat{\mathbf{x}}^-_j)
\end{equation}

The error for the \textit{posterior}, $\mathbf{e}_j$, can be written as:
\begin{equation}
\mathbf{e}_j = \mathbf{x}_j - \hat{\mathbf{x}}_j
\end{equation}

A common way to measure the accuracy of $\mathbf{e}_j$ is using the covariance matrix, denoted in the literature as $\mathbf{P}_j$. This can be expressed as follows:
\begin{equation}
\mathbf{P}_j = \mathbb{E}[\mathbf{e}_j \cdot \mathbf{e}_j]
\end{equation}

The Kalman filter attempts to select the Kalman Filter gain, $\mathbf{K}$, such that the \textit{posterior} covariance is minimised. Applying a classical optimisation technique for multivariate calculus, we arrive at the following expression:
\begin{equation}
\frac{\partial \mathbf{P}_j}{\partial \mathbf{K}_j} = \frac{\partial \mathbb{E}[(\mathbf{x}_j - \hat{\mathbf{x}}_j)(\mathbf{x}_j - \hat{\mathbf{x}}_j)^T]}{\partial \mathbf{K}_j} = 0
\end{equation}

Solving equation (12) yields the following result for the Kalman filter gain:
\begin{equation}
\mathbf{K}_j = \frac{\mathbf{P}_j \mathbf{H}^T}{\mathbf{H} \mathbf{P}_j \mathbf{H}^T + \mathbf{R}}
\end{equation}

The denominator of equation (13) contains the measurement noise, represented by matrix $\mathbf{R}$. In fact, the denominator is an important calculation step that maps the state prediction covariance, $\mathbf{P}_j$, into the measurement space - often this is expressed with the variable $\mathbf{S}$, that is:
\begin{equation}
\mathbf{S} = \mathbf{H} \mathbf{P}_j \mathbf{H}^T + \mathbf{R} 
\end{equation}

In addition to the \textit{posterior} error, $\mathbf{e}_j$, there is an error for the \textit{a priori}, denoted $\mathbf{e}^-_j$. The covariance matrix for $\mathbf{e}^-_j$ is given by $\mathbf{P}^-_j$. The final step to arriving at an algorithm for the Kalman filter is being able to recursively update both the \textit{posterior} and \textit{a priori} covariance matrices. The \textit{a priori} error covariance update is derived from considering the error expression $\mathbf{x}_j - \hat{\mathbf{x}}^-_j$, and is expressed using the movement noise matrix $\mathbf{Q}$. The expression is as follows:
\begin{equation}
\mathbf{P}^-_j = \mathbf{A} \mathbf{P}_{j-1} \mathbf{A}^T + \mathbf{Q}
\end{equation}

The \textit{posterior} update can be derived from equation (11), and is expressed as:
\begin{equation}
\mathbf{P}_j = (\mathbf{I} - \mathbf{K}_j \mathbf{H}) \mathbf{P}^-_j
\end{equation}

Equations (8), (9), (13), (14), (15), and (16) make up the Kalman Filter algorithm. A single pass of the Kalman Filter algorithm can be seen in Algorithm 1 - the pass starts with the \textit{a priori} state estimate update, and concludes with the \textit{posterior} error covariance update. The full algorithm would see the code run continuously, in a loop, iteratively updating state and covariance estimations.
\begin{algorithm}
\caption{Kalman Filter}
\begin{algorithmic}[1]
\State $\hat{\mathbf{x}}' \gets \mathbf{A} \hat{\mathbf{x}} + \mathbf{B} \mathbf{u}$ (A Priori State Estimate Update)
\State $\mathbf{P}' \gets \mathbf{A} \mathbf{P} \mathbf{A}^T + \mathbf{Q}$ (A Priori Error Covariance Update)
\State $\mathbf{S} \gets \mathbf{H} \mathbf{P}' \mathbf{H}^T + \mathbf{R}$ (Covariance Update In Measurement Space)
\State $\mathbf{K} \gets \mathbf{P}' \mathbf{H}^T \mathbf{S}^{-1}$ (Kalman Gain Update)
\State $\mathbf{x} \gets \mathbf{x}' + \mathbf{K}(\mathbf{z} - \mathbf{H} \mathbf{x}')$ (Posterior State Estimate Update Using Kalman Gain)
\State $\mathbf{P} \gets (\mathbf{I} - \mathbf{K} \mathbf{H}) \mathbf{P}'$ (Posterior Error Covariance Update)
\end{algorithmic}
\end{algorithm}

NEED TO TALK ABOUT EXTENDED KALMAN FILTER

\pagebreak

\subsection{Particle Filters}
Particle filters can be used to solve the global localisation problem, that is, it can localise a robot in an environment when its initial position is unknown. This section looks at a specific type of particle filter known as Monte Carlo Localisation (MCL). The central idea of MCL is the estimation of a posterior distribution across robot poses, often referred to as the \textit{belief}. The \textit{belief} is defined as probability density over the pose state space, which is conditioned on sensor measurement data, and odometric action data. Mobile robot pose, $\mathbf{x}$, is made up of location coordinates $x$ and $y$ and orientation $\theta$. Letting observation from a laser range finder be represented by $\mathbf{o}$, and odometric sensor data by represented by $\mathbf{a}$, we can mathematically express the belief as follows:
\begin{equation}
Bel(\mathbf{x}_t) = p(\mathbf{x}_t | \mathbf{o}_t, \mathbf{a}_{t-1}, \mathbf{o}_{t-1}, \mathbf{a}_{t-2},\ldots,\mathbf{o}_0)
\end{equation}

Particle filters estimate belief recursively, meaning that an update rule from time $t$ to time $t+1$ is required, and an initial belief is also needed. The initial belief characterizes the initial knowledge about the system state - if little is known about the initial system state, then a uniform distribution can be used over the state space. To derive the update equation we start by expressing (17) using Bayes rule:
\begin{equation}
Bel(\mathbf{x}_t) = \frac{p(\mathbf{o}_t | \mathbf{x}_t,\mathbf{a}_{t-1},\ldots,\mathbf{o}_0) \ p(\mathbf{x}_t | \mathbf{a}_{t-1},\ldots,\mathbf{o}_0)}{p(\mathbf{o}_t | \mathbf{a}_{t-1},\ldots,\mathbf{o}_0)}
\end{equation}

The denominator is a constant value relative to $\mathbf{x}_t$, and (4) can be written more compactly as:
\begin{equation}
Bel(\mathbf{x}_t) = \eta \ p(\mathbf{o}_t | \mathbf{x}_t,\mathbf{a}_{t-1},\ldots,\mathbf{o}_0) \ p(\mathbf{x}_t | \mathbf{a}_{t-1},\ldots,\mathbf{o}_0)
\end{equation}

where $\eta$ is a constant value:
\begin{equation}
\eta = p(\mathbf{o}_t | \mathbf{a}_{t-1},\ldots,\mathbf{o}_0)^{-1}
\end{equation}

A recursive relation seeks to provide an update at each time step. Information from the past is factored into the belief as changes occur. Therefore it can be reasoned that only new information presented to the system from current state is important when modifying the belief. This simplifying assumption, referred to as the \textit{Markov assumption}, suggests that future data is independent of past data given knowledge of the current state. Mathematically, this allows equation (5) to be re-written as:
\begin{equation}
Bel(\mathbf{x}_t) = \eta \ p(\mathbf{o}_t | \mathbf{x}_t) \ p(\mathbf{x}_t | \mathbf{a}_{t-1},\ldots,\mathbf{o}_0)
\end{equation} 

Partitioning over $\mathbf{x}_{t-1}$ equation (7) can be written as:
\begin{equation}
Bel(\mathbf{x}_t) = \eta \ p(\mathbf{o}_t | \mathbf{x}_t) \int p(\mathbf{x}_t, \mathbf{x}_{t-1} | \mathbf{a}_{t-1},\ldots,\mathbf{o}_0) \ d\mathbf{x}_{t-1}
\end{equation}

Applying Bayes' equation (8) can be written as:
\begin{equation}
Bel(\mathbf{x}_t) = \eta \ p(\mathbf{o}_t | \mathbf{x}_t) \int p(\mathbf{x}_{t} | \mathbf{x}_{t-1},\mathbf{a}_{t-1},\ldots,\mathbf{o}_0) \ p(\mathbf{x}_{t-1} | \mathbf{a}_{t-1},\ldots,\mathbf{o}_0) \ d\mathbf{x}_{t-1}
\end{equation}

Exploiting the Markov property again the first expression in the integral can be simplified. The second expression can be written using the $Bel$ notation as follows:
\begin{equation}
Bel(\mathbf{x}_t) = \eta \ p(\mathbf{o}_t | \mathbf{x}_t) \int p(\mathbf{x}_{t} | \mathbf{x}_{t-1},\mathbf{a}_{t-1}) \ Bel(\mathbf{x}_{t-1}) \ d\mathbf{x}_{t-1}
\end{equation}

There are two key components to equation (10):  the first is probability $p(\mathbf{x}_t| \mathbf{x}_{t-1}, \mathbf{a}_{t-1})$ which is referred to as the \textit{motion model}; and the second is the probability $p(\mathbf{o}_t|\mathbf{x}_t)$ which is referred to as the \textit{sensor model}.

\subsubsection{Motion model $p(\mathbf{x}_t| \mathbf{x}_{t-1}, \mathbf{a}_{t-1})$ and sensor model $p(\mathbf{o}_t|\mathbf{x}_t)$}
Under noise free ideal conditions the robot moves from state $\mathbf{x}_{t-1}$ to state $\mathbf{x}_t$ with certainty given some control action $\mathbf{a}_{t-1}$ - the assumption of idealness allows the use of kinematic equations to fully describe the robot's motion. As previously discussed, however, physical robot motion is subject to uncertainty since actuators are not ideal, which means there is uncertainty in pose $mathbf{x}_{t}$. The \textit{motion model}, $p(\mathbf{x}_t| \mathbf{x}_{t-1}, \mathbf{a}_{t-1})$, describes a posterior density over successors to pose $\mathbf{x}_{t-1}$. A graphical depiction of what this looks like can be seen in Figure XXXX, which shows the distribution over where the robot could be located given some control action. The image on the right shows the distribution of the robot location after moving 40 meters. The picture on the right shows a more complicated path. The darker regions of the distribution indicate more likely robot locations. 

\begin{figure}[h]
\centering
\includegraphics[scale=0.4]{motion_model}
\caption{text}
\end{figure}

The sensor model provides the probability, or likelihood, of obtaining the sensor measurements, $\mathbf{o}_t$, given a robot pose, $\mathbf{x}_t$ and control action $\mathbf{a}_{t-1}$, assuming that we have a known map. Sensors such as laser range finders are made up of multiple beams.

\subsubsection{MCL Implementation}
The state space for mobile robot localisation is continuous, meaning that implementing the recursive localisation equation shown in (24) is computationally intractable. Particle filter algorithms attempt to represent the belief $Bel(\mathbf{x}_t)$ using a set of $m$ weighted samples distributed according to $Bel(\mathbf{x}_t)$. Mathematically, we can express this as:
\begin{equation}
Bel(\mathbf{x}_t) \approx \{\mathbf{x}^{(i)}, \omega^{(i)} \}_{i=1,...,m}
\end{equation}

The sampled particles, $\mathbf{x}^{(i)}$, are discrete hypotheses of the robot's pose drawn from $Bel(\mathbf{x}_t)$. The $\omega^{(i)}$, called the \textit{importance factor}, are derived based on how likely the hypothesis particle is, given the sensor measurements and known map. The idea is that over time the set of sample particles converge on the true robot pose in the environment. This means that the algorithm needs to discard particles that are unlikely, and keep particles that are likely. Indeed the MCL algorithm can be thought of as featuring two distinct components:
\begin{enumerate}
\item \textbf{Motion and sensor update}: this phase sees the robot undergo a control action which is applied to its pose, as well as the pose of all particles. Additionally, sensor measurements are obtained, and then these sensor readings are used to determine new likelihood weights, $\omega$, for each of the particles.
\item \textbf{Resampling}: this phase allows us to discard particles which are not likely (low weights), and keep particles with high likelihood (i.e. large weights). This is undertaken by randomly sampling $m$ times from the pool of particles, with replacement. Higher $\omega$ weights mean it is more likely the particle will feature in the re-sampled set.
\end{enumerate}

The MCL algorithm pseudocode is shown in Algorithm 2 below.
\begin{algorithm}
\caption{Monte Carlo Localisation}
\begin{algorithmic}[1]
\Procedure{MCL}{$X_{t-1}$,$u_t$,$z_t$}
\State $\bar{X}_t = X_T = \emptyset$
\For{$m=1$ to $M$}
	\State $x^{[m]}_t = \text{motion\_update}(u_t, x^{[m]}_{t-1})$
	\State $\omega^{[m]}_t = \text{sensor\_update}(z_t, x^{[m]}_t)$
\EndFor
\For{$m=1$ to $M$}
	\State $\text{draw} \ x^{[m]}_t \ \text{from} \  \bar{X}_t \ \text{with probability} \propto \omega^{[m]}_t$
	\State $X_t = X_t + x^{[m]}_t$
\EndFor
\State $\text{return} \ X_t$
\EndProcedure
\end{algorithmic}
\end{algorithm}

\subsection{Comparison \& Model Selection}
Compare the two approaches and determine which approach was implemented to provide localisation for the two robot models.

\section{Simulations}
Gazebo, a physical simulation environment, was used to test an off-the-shelf implementation of MCL on two different mobile robot platforms. The first robot model was a benchmark designed to provide easy ROS implementation of the MCL package. Further,  the benchmark model utilised existing xml interfacing for Gazebo which guaranteed performance of the MCL package, for appropriate hyper-parameter selection. The second robot model was designed to assess how different physical locations for sensors might impact the performance of MCL. Physical dimensions of the robot were also altered, compared to the benchmark, to assess further performance changes in MCL.

WHAT WERE THE TESTS THAT WERE UNDERTAKEN - BASICALLY, A LOCATION WAS SET FOR THE ROBOT AUTOMATICALLY AND THE TEST WAS SATISFIED

\subsection{Benchmark Model}
\subsubsection{Model Design}
PROVIDE A BRIEF DESCRIPTION OF THE ROBOT MODEL INCLUDING SIZE AND SENSOR LAYOUT TALK ABOUT THE LOCOMOTION DRIVERS FOR THE ROBOT

PROVIDE A PICTURE OF THE ROBOT MODEL


\subsubsection{Packages Used}
TALK ABOUT THE PACKAGES THAT WERE USED FOR THE ROBOT AND THEIR CONFIGURATION

\subsubsection{Parameters}
TALK ABOUT THE HYPERPARAMETERS USED FOR THE 

\subsection{Personal Model}
PROVIDE A BRIEF DESCRIPTION OF THE ROBOT MODEL INCLUDING THE SIZE AND SENSOR LAYOUT TALK ABOUT THE LOCOMOTION DRIVERS FOR THE ROBOT

PROVIDE A PICTURE OF THE ROBOT MODEL

\section{Results}
\subsection{Localisation}
TALK ABOUT THE PERFORMANCE OF THE LOCALISATION ALGORITHM WAS THE ALGORITHM ABLE TO CONVERGE ON THE ROBOT POSE - SHOW PICTURES FROM BOTH ROBOT MODELS DID ONE CONVERGE FASTER THAN THE OTHER

ONCE LOCALISED WAS THE ROBOT ABLE TO SUCCESSFULLY NAVIGATE TO THE DESIRED LOCATION PROVIDED

\subsection{Technical Comparison}

\section{Discussion}

\subsection{Topics}

\section{Conculsion / Future Work}
\subsection{Modifications for Improvement}

\bibliography{my_bib}
\bibliographystyle{ieeetr}

\end{document}