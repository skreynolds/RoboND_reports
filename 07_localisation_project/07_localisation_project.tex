\documentclass[a4paper]{article}

%------------------------------------------------------------
\usepackage[a4paper, total={6in, 9in}]{geometry}
\usepackage{algorithm}
\usepackage[noend]{algpseudocode}
\usepackage{amsmath}
\usepackage{amsfonts}
\usepackage{booktabs}
\usepackage{caption}
\usepackage{enumitem}
\usepackage{graphicx}
\usepackage{float}
\usepackage{inconsolata}
\usepackage{listings}
\usepackage{pstricks-add}
\usepackage{siunitx}
\usepackage[most]{tcolorbox}
\usepackage{tikz}
\usepackage{epstopdf} %converting to PDF
\usepackage{hyperref}

\usetikzlibrary{shapes.geometric}

%------------------------------------------------------------
\graphicspath{{./fig/}}

%------------------------------------------------------------
\setlength{\parindent}{0in}

\lstdefinestyle{Python}{
	language        = Python,
	basicstyle      = \ttfamily,
	keywordstyle    = \color{blue},
	keywordstyle    = [2] \color{teal}, % just to check that it works
	stringstyle     = \color{green},
	commentstyle    = \color{red}\ttfamily
}

%------------------------------------------------------------
\newtcblisting[auto counter]{sexylisting}[2][]{sharp corners, 
    fonttitle=\bfseries, colframe=gray, listing only, 
    listing options={basicstyle=\ttfamily,language=Python}, 
    title=Listing \thetcbcounter: #2, #1}

%------------------------------------------------------------
\tikzstyle{block} = [draw, fill=blue!20, rectangle, 
    minimum height=3em, minimum width=3em]
\tikzstyle{sum} = [draw, fill=blue!20, circle, node distance=1cm]
\tikzstyle{input} = [coordinate]
\tikzstyle{output} = [coordinate]
\tikzstyle{pinstyle} = [pin edge={to-,thin,black}]

%------------------------------------------------------------

\begin{document}
\title{Localisation: Where Am I?}
\author{Shane Reynolds}
\maketitle

\section*{Abstract}

\section{Introduction}
Suppose a robot has an unknown pose in an environment for which it has a map. The robot takes sensor readings, and based on these observations, must infer a set of poses where it could be located in the environment. In robotics, this scenario is known as the \textit{localisation problem} \cite{Cox:1991, Wang:1988}. In simpler terms, localisation is the problem of estimating a mobile robot's location and orientation relative to its environment, given sensor data \cite{Thrun:2001}. This is not as straight forward as it appears given robot actuators are subject to small random perturbations in performance, and sensors provide imperfect measurement. Compounding these problems is the fact that the robot may not even know it's initial pose relative to the environment. This paper explores two approaches to solving the localisation problem, after providing a brief discussion on the common variations of the problem. The first of these solutions is the Extended Kalman Filter (EKF): an adaptation of the Kalman Filter, suited to the estimation of non-linear system responses. The second solution is a particle filter method called Monte Carlo Localisation (MCL). The paper concludes with an application of MCL in a Gazebo simulation using an off-the-shelf MCL package in ROS. The MCL implementation is trialled across two different robot models providing opportunities for discussion of implementation robustness, and an analysis of parameter tuning for reliable performance.

\section{Background}
The mobile robot localisation problem comes in three flavours. The simplest involves tracking the robot's pose relative to its environment - called \textit{position tracking}. This scenario requires an initial known estimate of the robot's pose relative to the environment. Robot actions require pose updates using noisey sensor data \cite{Thrun:1999}. Often initial pose estimates are unavailable - this scenario represents a more meaningful problem version called the \textit{global localisation problem}. The goal here is for the robot determine it's pose from scratch, given it is unaware of the initial pose. Finally, the most challenging problem type is referred to as the \textit{kidnapped robot problem} which sees a localised robot tele-ported to another location on the map without knowledge of the move. This is different to the \textit{global localisation problem} scenario because, after tele-porting, the robot incorrectly believes it is somewhere other than its current location. This final scenario is used to test whether a localisation algorithm can recover from a catastrophic failure.

\subsection{Kalman Filters}
Kalman Filters can be used to solve the simplest localisation problem: position tracking. In an ideal world, position tracking is a trivial task in which the robot knows it's starting location, and updates position with perfect actuation and perfect sensor readings. In the real world, however, this is not the case. Actuation is not perfect, and is subject to minor perturbations, or wheel slippage can occur. Furthermore, sensor readings are noisey. The implications are that both movement and measurement are imprecise and subject to stochastic errors. Consider the a mobile robot moving along a one dimensional trajectory. Let the discrete time position be $x_j$, at time $j$. We note that the position at time $j$ is dependent on the previous position at time $j-1$, denoted as $x_{j-1}$, plus any movement action taken by the robot, denoted as $u_j$. Additionally, as previously noted, the robot's actuators are not perfect and are subject to noise, $\omega_j$. We can write $x_j$ as follows:
\begin{equation}
x_j = a x_j + b u_j + \omega_j
\end{equation}

This description is sometimes easier to understand when visualised as a computational block diagram, shown in Figure 1.
\begin{figure}[h]
\centering
\input{./tikzpics/kf_1}
\caption{text}
\end{figure}

Almost always random phenomena are hidden from the observer behind a dynamical system - Kalman described this as follows:\\

\textit{A random function of time may be thought of as the output of a dynamic system excited by an independent Gaussian random process.} \cite{Kalman:1960}\\

This is true for robotic motion, given that we can only attempt to estimate the robot's stochastically perturbed motion, through the use of sensors like odometry, or laser range finders, which are subject to stochastic noise. Letting the measurement of signal $x_j$ be represented by $z_j$, we can write the following equation defining the measurement of $x_j$, subject to noise $\nu_j$, as:
\begin{equation}
z_j = h x_j + \nu_j
\end{equation} 

Equation (2) can be represented in a computational graph as follows:
\begin{figure}[h]
\centering
\input{./tikzpics/kf_2}
\caption{text}
\end{figure}

The fundamental problem that the Kalman Filter tries to answer is: how can an accurate estimate of a hidden stochastic signal be found when it is observed as the output of a dynamical system? The first step to answering this is to create a mathematical model of the system we can use to find an estimate of the measurement, $z_j$, which we call $\hat{z_j}$. This estimate is based on an estimation of the hidden variable, which we denote with $\hat{x}^-_j$. The mathematical model that provides these estimates does not factor in stochasticity seen in actual signals $x_j$ and $z_j$. This is the \textit{a priori} estimate of $x_j$, and is mathematically described as:
\begin{equation}
\hat{x}^-_j = a \hat{x}_{j-1} + b u_j
\end{equation}

The \textit{a priori} estimate is used to predict an output estimate,  $\hat{z}_j$. In turn, $\hat{z}_j$, is used to estimate the difference between predicted signal and the observed signal, referred to as the residual:
\begin{equation}
z_j - \hat{z}_j = z_j - h \hat{x}^-_j
\end{equation}

If the residual is small, then our estimate is good. If it is large then our estimate is not good. We can use the residual in (4) to update our \textit{a priori} estimate, $\hat{x}^-_j$:
\begin{equation}
\hat{x}_j = \hat{x}^-_j + k (z_j - h \hat{x}^-_j)
\end{equation}

A visualisation of the computational architecture for the process can be seen in Figure 3. This is a useful picture as it allows us to see the Kalman filter process decomposed into two distinct phases:
\begin{enumerate}
\item the state prediction phase in which the residual is used to update the \textit{a priori} providing a state prediction, known as the \textit{posterior belief}
\item the measurement update phase in which the \textit{posterior belief} is updated with control actions $u_j$ and used as the new \textit{a priori}, which is combined with sensor readings to compute the new residual.
\end{enumerate}, 
\begin{figure}[h]
\centering
\input{./tikzpics/kf_3}
\caption{text}
\end{figure}

The task of determining $k$, used to refine our estimate, is at the heart of the Kalman filtering process. This is not a trivial task. Further, our problem is complicated when considering robotic motion in multiple dimensions - so far, estimation has only been considered for a 1D problem. Most mobile robots move in 2D, and we may also want to estimate other important locomotion variables such as velocity. Suppose that state was now represented as vector of variables such as position in 2D, including velocity. We define this using bold typeface $\mathbf{x}_j$. Similarly, control actions are represented as $\mathbf{u}_j$, and the measurement for each state variable in $\mathbf{x}_j$ is represented by $\mathbf{z}_j$. Without loss of generality equation (1) becomes:
\begin{equation}
\mathbf{x}_j = \mathbf{A} \mathbf{x}_j + \mathbf{B} \mathbf{u}_j + \boldsymbol{\omega}_j
\end{equation}

Similarly, equation (2) becomes:
\begin{equation}
\mathbf{z}_j = \mathbf{H} \mathbf{x}_j + \boldsymbol{\nu}_j
\end{equation}

The \textit{a priori} estimate of the state variable, shown in equation (3), in multidimensional form, is given by:
\begin{equation}
\hat{\mathbf{x}}^-_j = \mathbf{A} \hat{\mathbf{x}}_j + \mathbf{B} \mathbf{u}_j
\end{equation}

The \textit{a priori} update, shown in equation (5) is given by:
\begin{equation}
\hat{\mathbf{x}}_j = \hat{\mathbf{x}}^-_j + \mathbf{K}_j (\mathbf{z}_j - \mathbf{H} \hat{\mathbf{x}}^-_j)
\end{equation}

The error for the \textit{posterior}, $\mathbf{e}_j$, can be written as:
\begin{equation}
\mathbf{e}_j = \mathbf{x}_j - \hat{\mathbf{x}}_j
\end{equation}

A common way to measure the accuracy of $\mathbf{e}_j$ is using the covariance matrix, denoted in the literature as $\mathbf{P}_j$. This can be expressed as follows:
\begin{equation}
\mathbf{P}_j = \mathbb{E}[\mathbf{e}_j \cdot \mathbf{e}_j]
\end{equation}

The Kalman filter attempts to select the Kalman Filter gain, $\mathbf{K}$, such that the \textit{posterior} covariance is minimised. Applying a classical optimisation technique for multivariate calculus, we arrive at the following expression:
\begin{equation}
\frac{\partial \mathbf{P}_j}{\partial \mathbf{K}_j} = \frac{\partial \mathbb{E}[(\mathbf{x}_j - \hat{\mathbf{x}}_j)(\mathbf{x}_j - \hat{\mathbf{x}}_j)^T]}{\partial \mathbf{K}_j} = 0
\end{equation}

Solving equation (12) yields the following result for the Kalman filter gain:
\begin{equation}
\mathbf{K}_j = \frac{\mathbf{P}_j \mathbf{H}^T}{\mathbf{H} \mathbf{P}_j \mathbf{H}^T + \mathbf{R}}
\end{equation}

The denominator of equation (13) contains the measurement noise, represented by matrix $\mathbf{R}$. In fact, the denominator is an important calculation step that maps the state prediction covariance, $\mathbf{P}_j$, into the measurement space - often this is expressed with the variable $\mathbf{S}$, that is:
\begin{equation}
\mathbf{S} = \mathbf{H} \mathbf{P}_j \mathbf{H}^T + \mathbf{R} 
\end{equation}

In addition to the \textit{posterior} error, $\mathbf{e}_j$, there is an error for the \textit{a priori}, denoted $\mathbf{e}^-_j$. The covariance matrix for $\mathbf{e}^-_j$ is given by $\mathbf{P}^-_j$. The final step to arriving at an algorithm for the Kalman filter is being able to recursively update both the \textit{posterior} and \textit{a priori} covariance matrices. The \textit{a priori} error covariance update is derived from considering the error expression $\mathbf{x}_j - \hat{\mathbf{x}}^-_j$, and is expressed using the movement noise matrix $\mathbf{Q}$. The expression is as follows:
\begin{equation}
\mathbf{P}^-_j = \mathbf{A} \mathbf{P}_{j-1} \mathbf{A}^T + \mathbf{Q}
\end{equation}

The \textit{posterior} update can be derived from equation (11), and is expressed as:
\begin{equation}
\mathbf{P}_j = (\mathbf{I} - \mathbf{K}_j \mathbf{H}) \mathbf{P}^-_j
\end{equation}

Equations (8), (9), (13), (14), (15), and (16) make up the Kalman Filter algorithm. A single pass of the Kalman Filter algorithm can be seen in Algorithm 1 - the pass starts with the \textit{a priori} state estimate update, and concludes with the \textit{posterior} error covariance update. The full algorithm would see the code run continuously, in a loop, iteratively updating state and covariance estimations.
\begin{algorithm}
\caption{Kalman Filter}
\begin{algorithmic}[1]
\State $\hat{\mathbf{x}}' \gets \mathbf{A} \hat{\mathbf{x}} + \mathbf{B} \mathbf{u}$ (A Priori State Estimate Update)
\State $\mathbf{P}' \gets \mathbf{A} \mathbf{P} \mathbf{A}^T + \mathbf{Q}$ (A Priori Error Covariance Update)
\State $\mathbf{S} \gets \mathbf{H} \mathbf{P}' \mathbf{H}^T + \mathbf{R}$ (Covariance Update In Measurement Space)
\State $\mathbf{K} \gets \mathbf{P}' \mathbf{H}^T \mathbf{S}^{-1}$ (Kalman Gain Update)
\State $\mathbf{x} \gets \mathbf{x}' + \mathbf{K}(\mathbf{z} - \mathbf{H} \mathbf{x}')$ (Posterior State Estimate Update Using Kalman Gain)
\State $\mathbf{P} \gets (\mathbf{I} - \mathbf{K} \mathbf{H}) \mathbf{P}'$ (Posterior Error Covariance Update)
\end{algorithmic}
\end{algorithm}

NEED TO TALK ABOUT EXTENDED KALMAN FILTER

\pagebreak

\subsection{Particle Filters}
Particle filters can be used to solve the global localisation problem, that is, it can localise a robot in an environment when its initial position is unknown. This section looks at a specific type of particle filter known as Monte Carlo Localisation (MCL). The central idea of MCL is the estimation of a posterior distribution across robot poses, often referred to as the \textit{belief}. The \textit{belief} is defined as probability density over the pose state space, which is conditioned on sensor measurement data, and odometric action data. Mobile robot pose, $\mathbf{x}$, is made up of location coordinates $x$ and $y$ and orientation $\theta$. Letting observation from a laser range finder be represented by $\mathbf{o}$, and odometric sensor data by represented by $\mathbf{a}$, we can mathematically express the belief as follows:
\begin{equation}
Bel(\mathbf{x}_t) = p(\mathbf{x}_t | \mathbf{o}_t, \mathbf{a}_{t-1}, \mathbf{o}_{t-1}, \mathbf{a}_{t-2},\ldots,\mathbf{o}_0)
\end{equation}

Particle filters estimate belief recursively, meaning that an update rule from time $t$ to time $t+1$ is required, and an initial belief is also needed. The initial belief characterizes the initial knowledge about the system state - if little is known about the initial system state, then a uniform distribution can be used over the state space. To derive the update equation we start by expressing (17) using Bayes rule:
\begin{equation}
Bel(\mathbf{x}_t) = \frac{p(\mathbf{o}_t | \mathbf{x}_t,\mathbf{a}_{t-1},\ldots,\mathbf{o}_0) \ p(\mathbf{x}_t | \mathbf{a}_{t-1},\ldots,\mathbf{o}_0)}{p(\mathbf{o}_t | \mathbf{a}_{t-1},\ldots,\mathbf{o}_0)}
\end{equation}

The denominator is a constant value relative to $\mathbf{x}_t$, and (4) can be written more compactly as:
\begin{equation}
Bel(\mathbf{x}_t) = \eta \ p(\mathbf{o}_t | \mathbf{x}_t,\mathbf{a}_{t-1},\ldots,\mathbf{o}_0) \ p(\mathbf{x}_t | \mathbf{a}_{t-1},\ldots,\mathbf{o}_0)
\end{equation}

where $\eta$ is a constant value:
\begin{equation}
\eta = p(\mathbf{o}_t | \mathbf{a}_{t-1},\ldots,\mathbf{o}_0)^{-1}
\end{equation}

A recursive relation seeks to provide an update at each time step. Information from the past is factored into the belief as changes occur. Therefore it can be reasoned that only new information presented to the system from current state is important when modifying the belief. This simplifying assumption, referred to as the \textit{Markov assumption}, suggests that future data is independent of past data given knowledge of the current state. Mathematically, this allows equation (5) to be re-written as:
\begin{equation}
Bel(\mathbf{x}_t) = \eta \ p(\mathbf{o}_t | \mathbf{x}_t) \ p(\mathbf{x}_t | \mathbf{a}_{t-1},\ldots,\mathbf{o}_0)
\end{equation} 

Partitioning over $\mathbf{x}_{t-1}$ equation (7) can be written as:
\begin{equation}
Bel(\mathbf{x}_t) = \eta \ p(\mathbf{o}_t | \mathbf{x}_t) \int p(\mathbf{x}_t, \mathbf{x}_{t-1} | \mathbf{a}_{t-1},\ldots,\mathbf{o}_0) \ d\mathbf{x}_{t-1}
\end{equation}

Applying Bayes' equation (8) can be written as:
\begin{equation}
Bel(\mathbf{x}_t) = \eta \ p(\mathbf{o}_t | \mathbf{x}_t) \int p(\mathbf{x}_{t} | \mathbf{x}_{t-1},\mathbf{a}_{t-1},\ldots,\mathbf{o}_0) \ p(\mathbf{x}_{t-1} | \mathbf{a}_{t-1},\ldots,\mathbf{o}_0) \ d\mathbf{x}_{t-1}
\end{equation}

Exploiting the Markov property again the first expression in the integral can be simplified. The second expression can be written using the $Bel$ notation as follows:
\begin{equation}
Bel(\mathbf{x}_t) = \eta \ p(\mathbf{o}_t | \mathbf{x}_t) \int p(\mathbf{x}_{t} | \mathbf{x}_{t-1},\mathbf{a}_{t-1}) \ Bel(\mathbf{x}_{t-1}) \ d\mathbf{x}_{t-1}
\end{equation}

There are two key components to equation (10):  the first is probability $p(\mathbf{x}_t| \mathbf{x}_{t-1}, \mathbf{a}_{t-1})$ which is referred to as the \textit{motion model}; and the second is the probability $p(\mathbf{o}_t|\mathbf{x}_t)$ which is referred to as the \textit{sensor model}.

\subsubsection{Motion model $p(\mathbf{x}_t| \mathbf{x}_{t-1}, \mathbf{a}_{t-1})$ and sensor model $p(\mathbf{o}_t|\mathbf{x}_t)$}
Under noise free ideal conditions the robot moves from state $\mathbf{x}_{t-1}$ to state $\mathbf{x}_t$ with certainty given some control action $\mathbf{a}_{t-1}$ - the assumption of idealness allows the use of kinematic equations to fully describe the robot's motion. As previously discussed, however, physical robot motion is subject to uncertainty since actuators are not ideal, which means there is uncertainty in pose $mathbf{x}_{t}$. The \textit{motion model}, $p(\mathbf{x}_t| \mathbf{x}_{t-1}, \mathbf{a}_{t-1})$, describes a posterior density over successors to pose $\mathbf{x}_{t-1}$. A graphical depiction of what this looks like can be seen in Figure XXXX, which shows the distribution over where the robot could be located given some control action. The image on the right shows the distribution of the robot location after moving 40 meters. The picture on the right shows a more complicated path. The darker regions of the distribution indicate more likely robot locations. 

\begin{figure}[h]
\centering
\includegraphics[scale=0.4]{motion_model}
\caption{text}
\end{figure}

The sensor model provides the probability, or likelihood, of obtaining the sensor measurements, $\mathbf{o}_t$, given a robot pose, $\mathbf{x}_t$ and control action $\mathbf{a}_{t-1}$, assuming that we have a known map. Sensors such as laser range finders are made up of multiple beams.

\subsubsection{MCL Implementation}
The state space for mobile robot localisation is continuous, meaning that implementing the recursive localisation equation shown in (24) is computationally intractable. Particle filter algorithms attempt to represent the belief $Bel(\mathbf{x}_t)$ using a set of $m$ weighted samples distributed according to $Bel(\mathbf{x}_t)$. Mathematically, we can express this as:
\begin{equation}
Bel(\mathbf{x}_t) \approx \{\mathbf{x}^{(i)}, \omega^{(i)} \}_{i=1,...,m}
\end{equation}

The sampled particles, $\mathbf{x}^{(i)}$, are discrete hypotheses of the robot's pose drawn from $Bel(\mathbf{x}_t)$. The $\omega^{(i)}$, called the \textit{importance factor}, are derived based on how likely the hypothesis particle is, given the sensor measurements and known map. The idea is that over time the set of sample particles converge on the true robot pose in the environment. This means that the algorithm needs to discard particles that are unlikely, and keep particles that are likely. Indeed the MCL algorithm can be thought of as featuring two distinct components:
\begin{enumerate}
\item \textbf{Motion and sensor update}: this phase sees the robot undergo a control action which is applied to its pose, as well as the pose of all particles. Additionally, sensor measurements are obtained, and then these sensor readings are used to determine new likelihood weights, $\omega$, for each of the particles.
\item \textbf{Resampling}: this phase allows us to discard particles which are not likely (low weights), and keep particles with high likelihood (i.e. large weights). This is undertaken by randomly sampling $m$ times from the pool of particles, with replacement. Higher $\omega$ weights mean it is more likely the particle will feature in the re-sampled set.
\end{enumerate}

The MCL algorithm pseudocode is shown in Algorithm 2 below.
\begin{algorithm}
\caption{Monte Carlo Localisation}
\begin{algorithmic}[1]
\Procedure{MCL}{$X_{t-1}$,$u_t$,$z_t$}
\State $\bar{X}_t = X_T = \emptyset$
\For{$m=1$ to $M$}
	\State $x^{[m]}_t = \text{motion\_update}(u_t, x^{[m]}_{t-1})$
	\State $\omega^{[m]}_t = \text{sensor\_update}(z_t, x^{[m]}_t)$
\EndFor
\For{$m=1$ to $M$}
	\State $\text{draw} \ x^{[m]}_t \ \text{from} \  \bar{X}_t \ \text{with probability} \propto \omega^{[m]}_t$
	\State $X_t = X_t + x^{[m]}_t$
\EndFor
\State $\text{return} \ X_t$
\EndProcedure
\end{algorithmic}
\end{algorithm}

\subsection{Comparison \& Model Selection}
Compare the two approaches and determine which approach was implemented to provide localisation for the two robot models.

\section{Simulations}
Gazebo, a physical simulation environment, was used to test an off-the-shelf implementation of MCL on two different mobile robot platforms. The first robot model was a benchmark designed to provide easy ROS implementation of the MCL package. Further, the benchmark model utilised existing xml interfacing for Gazebo guaranteeing performance of the MCL package, with minimal parameter configuration. The second robot model was designed to assess how different physical locations for sensors might impact the performance of MCL. Additionally, physical robot dimensions were altered, compared to the benchmark, to assess performance changes in MCL. MCL performance was tested by sending an identical pose, including location and orientation, in the environment to each robot model. Performance was evaluated by measuring: how long it took the robot model to navigate to the desired pose; how quickly the MCL algorithm localised the robot in it's environment; and how close the final robot pose was to the desired pose on experiment termination.

\subsection{Benchmark Model}
\subsubsection{Model Design}
The benchmark robot model was a simple design, consisting of a rectangular prism chassis, along with two cylindrical wheels placed in a differential drive configuration in the middle of the chassis. Frictionless, semi-spherical, casters were placed in symmetrical locations on either end of the chassis to ensure stability. A camera, modelled geometrically with a red cube, was placed on the front of the chassis. A laser range finder was placed on top of the chassis, towards the camera location.
\begin{figure}[h]
\centering
\frame{\includegraphics[scale=0.4]{benchmark_model}}
\caption{text}
\end{figure}

\begin{minipage}{0.45\textwidth}
Figure XXXX shows the robot model loaded into an empty world using Gazebo. The robot was equipped with a differential drive controller, called \texttt{libgazebo\_ros\_diff\_drive.so}, which allowed ROS to control the robot wheels. Similarly, controllers for the camera and laser range finder were equipped which were called \texttt{libgazebo\_ros\_camera.so} and \texttt{libgazebo\_ros\_laser.so}, respectively. The robot dimensions can be seen in Table XXXX.
\end{minipage}
\hspace{1cm}
\begin{minipage}{0.45\textwidth}
\centering
\captionof{table}{text}
\begin{tabular}{lc}
\toprule
\textbf{Dimension} & \textbf{Measurement ($\si{\meter}$)} \\
\midrule
Chassis Length & 0.4\\
Chassis Width & 0.2\\
Chassis Height & 0.1\\
Wheel Radius & 0.1\\
Wheel Placement & Center\\
\bottomrule
\end{tabular}
\end{minipage}


\subsubsection{Personal Model}
An alternative model was constructed using the benchmark design as a starting point. The original chassis was retained, however, the cylindrical wheels were shifted to the chassis rear in a differential drive configuration. Two frictionless semi-spherical casters were symmetrically at either end of the chassis. The camera was left in its original location. To provided an elevated location for the laser range finder the height of the robot chassis at the rear was elevated.
\begin{figure}[h]
\centering
\frame{\includegraphics[scale=0.5]{shane_model}}
\caption{text}
\end{figure}

\begin{minipage}{0.45\textwidth}
Figure XXXX shows the robot model loaded into an empty world using Gazebo. The robot was equipped with controllers for the differential drive, camera, and laser range finder identical to the benchmark model. The robot dimensions can be seen in Table XXXX.
\end{minipage}
\hspace{1cm}
\begin{minipage}{0.45\textwidth}
\centering
\captionof{table}{text}
\begin{tabular}{lc}
\toprule
\textbf{Dimension} & \textbf{Measurement ($\si{\meter}$)} \\
\midrule
Chassis Length & 0.4\\
Chassis Width & 0.2\\
Chassis Height & 0.1\\
Wheel Radius & 0.1\\
Wheel Placement & Rear\\
\bottomrule
\end{tabular}
\end{minipage}

\subsection{Packages}
TALK BRIEFLY ABOUT THE USE OF PACKAGES IN THE SET UP
\subsubsection{\texttt{amcl} package}
The \texttt{amcl} package is a localisation system for a robot traversing 2D map topologies, which is implemented in ROS. The package implements an Monte Carlo localisation approach that uses a particle filter to track the pose of the robot for a given known map. Unlike standard MCL algorithms, this package implements an adaptive filter, which changes the number of sampled particles dynamically to ensure that error introduced by the sample-based representation is bounded.

Some of the more important parameters for this package include:
\begin{itemize}
\item \textbf{\texttt{min\_particles}} and \textbf{\texttt{max\_particles}}: amcl dynamically adjusts the number of particles for each iteration, between some given range. A range with a high maximum may be too computationally expensive, for a given system.
\item \textbf{\texttt{update\_min\_a}} and \textbf{\texttt{update\_min\_d}}: upon receiving a laser scan, amcl checks the linear and angular displacement of the robot from the last laser scan and will only provide a filter update if these values are greater than the values specified in these parameters 
\item \textbf{\texttt{transform\_tolerance}}: the duration for which a published transform is valid
\item \textbf{\texttt{laser\_min\_range}} and \textbf{\texttt{laser\_max\_range}}: define the minimum and maximum scan ranges that will be considered for the laser range finder 
\item \textbf{\texttt{laser\_max\_beams}}: how many evenly spaced beams in each scan to be used when updating the filter
\end{itemize}

\subsubsection{\texttt{move\_base} package}
The \texttt{move\_base} package provides the robot with a navigation and path planning tool. Given a goal in the world, the \texttt{move\_base} package will provide action to reach it with a mobile base. This is comprised of a global path planner, and a local path planner. The \texttt{mve\_base} node, once initialised, will also maintain two costmaps: one for the global planner, and one for the local planner. These maps are integral to accomplish navigation tasks. The \texttt{move\_base} node subscribes to a number of different topics. These include:
\begin{itemize}
\item an environment map provided by a map server;
\item laser scans from a laser range finder;
\item point cloud data from RGBD cameras;
\item odometric data from the robot odometry;
\item sensor transforms from a transform topic; and
\item transform updates from amcl nodes
\end{itemize}

The \texttt{move\_base} node receives a simple goal pose, and outputs a series of commands to the robot's base controller in order to achieve the input goal. The visual graph depicting the navigation stack set up can be seen in Figure XXXX.
\begin{figure}[h]
\centering
\includegraphics[scale=0.7]{move_base}
\caption{text}
\end{figure}

Some of the more important parameters for this package include:
\begin{itemize}
\item \textbf{\texttt{controller\_frequency}}: the rate in $\si{\hertz}$ at which to run the control loop and send velocity commands to the base
\item \textbf{\texttt{update\_frequency}}: the frequency in $\si{\hertz}$ for the map to be updated
\item \textbf{\texttt{publish\_frequency}}: the frequency in $\si{\hertz}$ for the map to be published
\item \textbf{\texttt{inflation\_radius}}: the radius in meters to which the map inflates obstacle cost values
\item \textbf{\texttt{obstacle\_range}}: the maximum range in meters at which to insert obstacles into the costmap using sensor data
\item \textbf{\texttt{raytrace\_range}}: the maximum range in meters at which to raytrace out obstacles from the map using sensor data
\end{itemize}

\subsection{Parameter Tuning}
\begin{minipage}{0.55\textwidth}
Parameters were tuned for the benchmark model using trial and error. This was done iteratively until a set of parameters were found that allowed basic error free movement over short linear distances. Parameters were tuned one at a time. This was achieved by entering a test value for a single parameter to the model configuration. The model was then loaded into the world, with an active \texttt{amcl} and \texttt{move\_base} node, and given a desired pose a short distance from the original pose. Performance was evaluated visually. This process was continued until satisfactory performance was obtained for the benchmark model - the tuned parameter values can be seen in Table 1.
\end{minipage}
\hspace{0.75cm}
\begin{minipage}{0.35\textwidth}
\centering
\captionof{table}{text}
\begin{tabular}{lr}
\toprule
\textbf{Parameter} & \textbf{Value}\\
\midrule
\texttt{controller\_frequency} & 10.0 \\
\texttt{update\_frequency} & 20.0 \\
\texttt{publish\_frequency} & 20.0 \\
\texttt{transform\_tolerance} & 0.2 \\
\texttt{inflation\_radius} & 0.3 \\
\texttt{obstacle\_range} & 8.0\\
\texttt{raytrace\_range} & 10.0\\
\bottomrule
\end{tabular}
\end{minipage}



\section{Results}
Robot models were tested using the same parameter configuration for \texttt{move\_base} and \texttt{amcl}. The test required robot navigation to a location in the environment. Both the benchmark and personal models were able to successfully localise in the environment, and build local costmap used to navigate around environment obstacles. Figures XXXX, XXXX, and XXXX show the physical environment, the given ground truth map, and the local cost map, respectively.\\

\begin{minipage}{0.45\textwidth}
\centering
\frame{\includegraphics[height=4cm]{cost_map_1}}
\captionof{figure}{text}
\end{minipage}
\hspace{1cm}
\begin{minipage}{0.45\textwidth}
\centering
\frame{\includegraphics[height=4cm]{cost_map_2}}
\captionof{figure}{text}
\end{minipage}

\begin{figure}[h]
\centering
\frame{\includegraphics[height=4cm]{cost_map_3}}
\captionof{figure}{text}
\end{figure}

\begin{table}[h]
\centering
\caption{text}
\begin{tabular}{crrcrr}
\toprule
& \multicolumn{2}{c}{\textbf{Benchmark Model}} & & \multicolumn{2}{c}{\textbf{Personal Model}} \\
\cline{2-3} \cline{5-6}
\textbf{Trial} & \textbf{Localisation} & \textbf{Goal} & & \textbf{Localisation} & \textbf{Goal} \\
\midrule
1 & \texttt{stuck} & \texttt{stuck} & & 0.48 & 1.36 \\
2 & \texttt{stuck} & \texttt{stuck} & & 0.47 & 1.36 \\
3 & \texttt{stuck} & \texttt{stuck} & & \texttt{stuck} & \texttt{stuck} \\
4 & 0.39 & 1.21 & & 0.52 & 1.37 \\
5 & 0.36 & 1.21 & & \texttt{stuck} & \texttt{stuck} \\
\bottomrule
\end{tabular}
\end{table}

\newpage

\begin{minipage}{0.45\textwidth}
\centering
\frame{\includegraphics[height=4.5cm]{og_model_1}}
\captionof{figure}{text}
\end{minipage}
\hspace{1cm}
\begin{minipage}{0.45\textwidth}
\centering
\frame{\includegraphics[height=4.5cm]{new_model_1}}
\captionof{figure}{text}
\end{minipage}

\begin{minipage}{0.45\textwidth}
\centering
\frame{\includegraphics[height=4.5cm]{og_model_2}}
\captionof{figure}{text}
\end{minipage}
\hspace{1cm}
\begin{minipage}{0.45\textwidth}
\centering
\frame{\includegraphics[height=4.5cm]{new_model_2}}
\captionof{figure}{text}
\end{minipage}

\begin{minipage}{0.45\textwidth}
\centering
\frame{\includegraphics[height=4.5cm]{og_model_3}}
\captionof{figure}{text}
\end{minipage}
\hspace{1cm}
\begin{minipage}{0.45\textwidth}
\centering
\frame{\includegraphics[height=4.5cm]{new_model_3}}
\captionof{figure}{text}
\end{minipage}

TALK ABOUT THE PERFORMANCE OF THE LOCALISATION ALGORITHM WAS THE ALGORITHM ABLE TO CONVERGE ON THE ROBOT POSE - SHOW PICTURES FROM BOTH ROBOT MODELS DID ONE CONVERGE FASTER THAN THE OTHER

ONCE LOCALISED WAS THE ROBOT ABLE TO SUCCESSFULLY NAVIGATE TO THE DESIRED LOCATION PROVIDED

PROVIDE PICTURES OF THE ROBOT AT THE START OF THE GOAL SEEKING, DURING THE GOAL SEEKING, AND AT THE END OF THE GOAL SEEKING

PROVIDE A TABLE OF INTERESTING RESULTS IN TERMS OF TIMES TAKEN TO ACHIEVE

\section{Discussion}
WHICH ROBOT PERFORMED BETTER? WHY WAS THIS THE CASE?

\section{Conculsion / Future Work}
WHAT NEEDS TO BE INVESTIGATED FURTHER? WHAT PROBLEMS DID THE ROBOT ENCOUNTER? WHAT OTHER VARIANTS OF THE LOCALISATION PROBLEM COULD BE EXPLORED? 

\newpage

\bibliography{my_bib}
\bibliographystyle{ieeetr}

\end{document}