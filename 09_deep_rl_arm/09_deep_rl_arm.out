\BOOKMARK [1][-]{section.1}{Introduction}{}% 1
\BOOKMARK [1][-]{section.2}{Background}{}% 2
\BOOKMARK [2][-]{subsection.2.1}{Markov Decision Process}{section.2}% 3
\BOOKMARK [2][-]{subsection.2.2}{Policy}{section.2}% 4
\BOOKMARK [2][-]{subsection.2.3}{Return}{section.2}% 5
\BOOKMARK [2][-]{subsection.2.4}{Value Function \046 Action Value Function}{section.2}% 6
\BOOKMARK [2][-]{subsection.2.5}{Reinforcement Learning Algorithms}{section.2}% 7
\BOOKMARK [3][-]{subsubsection.2.5.1}{Monte Carlo Methods}{subsection.2.5}% 8
\BOOKMARK [3][-]{subsubsection.2.5.2}{Temporal Difference Methods}{subsection.2.5}% 9
\BOOKMARK [2][-]{subsection.2.6}{Deep Reinforcement Learning}{section.2}% 10
\BOOKMARK [3][-]{subsubsection.2.6.1}{Experience Replay}{subsection.2.6}% 11
\BOOKMARK [3][-]{subsubsection.2.6.2}{Fixed Q-Targets}{subsection.2.6}% 12
\BOOKMARK [1][-]{section.3}{Robotic Arm Reinforcement Learning Problem}{}% 13
\BOOKMARK [1][-]{section.4}{Collisions}{}% 14
\BOOKMARK [1][-]{section.5}{Reward Function}{}% 15
\BOOKMARK [1][-]{section.6}{Hyperparameters}{}% 16
\BOOKMARK [1][-]{section.7}{Results}{}% 17
\BOOKMARK [1][-]{section.8}{Discussion}{}% 18
\BOOKMARK [1][-]{section.9}{Future Work}{}% 19
