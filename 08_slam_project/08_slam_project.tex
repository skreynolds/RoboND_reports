\documentclass[a4paper]{article}

%------------------------------------------------------------
\usepackage[a4paper, total={6in, 9in}]{geometry}
\usepackage{amsmath}
\usepackage{booktabs}
\usepackage{caption}
\usepackage{enumitem}
\usepackage{graphicx}
\usepackage{float}
\usepackage{inconsolata}
\usepackage{listings}
\usepackage{pstricks-add}
\usepackage{siunitx}
\usepackage[most]{tcolorbox}
\usepackage{tikz}
\usepackage{epstopdf} %converting to PDF
\usepackage{hyperref}

\usetikzlibrary{shapes.geometric}
\usetikzlibrary{calc}

%------------------------------------------------------------
\graphicspath{{./fig/}}

%------------------------------------------------------------
\setlength{\parindent}{0in}

\lstdefinestyle{Python}{
	language        = Python,
	basicstyle      = \ttfamily,
	keywordstyle    = \color{blue},
	keywordstyle    = [2] \color{teal}, % just to check that it works
	stringstyle     = \color{green},
	commentstyle    = \color{red}\ttfamily
}

%------------------------------------------------------------
\newtcblisting[auto counter]{sexylisting}[2][]{sharp corners, 
    fonttitle=\bfseries, colframe=gray, listing only, 
    listing options={basicstyle=\ttfamily,language=Python}, 
    title=Listing \thetcbcounter: #2, #1}

%------------------------------------------------------------
\tikzstyle{block} = [draw, fill=blue!20, rectangle, 
    minimum height=3em, minimum width=3em]
\tikzstyle{sum} = [draw, fill=blue!20, circle, node distance=1cm]
\tikzstyle{input} = [coordinate]
\tikzstyle{output} = [coordinate]
\tikzstyle{pinstyle} = [pin edge={to-,thin,black}]

%------------------------------------------------------------

\begin{document}
\title{SLAM: Map My World}
\author{Shane Reynolds}
\maketitle

\section*{Abstract}

\section{Introduction}
Consider a robot in an unknown environment, with no known map. The robot takes sensor readings and experiences control actions. Based on these observations and actions, the robot must construct a map and localise itself within the map. In robotics, this scenario is known as the \textit{simultaneous localisation and mapping problem}, or SLAM. In simpler terms, using sensor readings and control data, SLAM concurrently constructs an environment map, and determines the robots location and orientation within that map. This is an important problem since odometric data is subject to small perturbations which are introduced from wheel slippage and sensor noise - often refered to as odometric drift. Mapping allows a robot to revisit previously mapped terrain and reset any localisation error. Also, location and orientation within a given map are normally used as inputs for higher order functions like path planning. The problem is more difficult to solve than localisation with known poses since high dimensionality of map spaces can often lead to computational intractabilityy. This paper explores two approaches to solving SLAM. The first of these solutions is called FastSLAM which employs a combination of Extended Kalman Filters(EKF) and Monte Carlo Localisation (MCL) to solve the problem. The second approach is called GraphSLAM, which solves the problem by optimising a graph structure built by the algorithm. The paper concludes with an application of GraphSLAM in a Gazebo simulation using an off-the-shelf implementation called RTAB-Map in ROS. The GraphSLAM implementation is tested across two different environments providing opportunities for discussion of the algorithm robustness.

\section{Background}
Robot localisation aims to determine, for some discrete time step $t$, a distribution of the robot's pose, $x_t$, given a series of observations, $z_{1:t}$, control actions, $u_{1:t}$, and a map, $m$. The localisation problem is often expressed, using conditional probability notation, as follows:
\begin{equation}
p(x_t | z_{1:t}, m, u_{1:t})
\end{equation}

Mapping of an environment is the problem of determining a distribution over all possible map configurations, $m$, given a series of observations, $z_{1:t}$, and known robot poses, $x_{1:t}$. The mapping problem is often expressed, using conditional probability notation, as follows:
\begin{equation}
p(m | z_{1:t}, x_{1:t})
\end{equation}

Generally, a robot has neither the map, nor known poses, meaning that posteriors for both the map space and the robot's pose need to be determined. Equations (1) and (2) show these distributions are dependent on each other - evaluation of pose posterior requires the map, and evaluation of map posterior requires pose. This is often referred to as the chicken and egg problem. The main implication is that approaches designed to solve equations (1) and (2) cannot be readily applied in their current forms. Further, the problem can no longer be sufficiently expressed using these equations. SLAM, as the name suggests, determines these the map, $m$, and pose, $x_t$, simultaneously given sensor observations, $z_{1:t}$, and control actions, $u_{1:t}$. Mathematically, this is expressed as:
\begin{equation}
p(x_t, m | z_{1:t}, u_{1:t})
\end{equation}

Equation (3) is the equation for the \textit{online} SLAM problem, which is only concerned with determining the robot's current location. Another variation of the SLAM problem, which is more difficult to solve, is the \textit{full} SLAM problem. The \textit{full} SLAM problem seeks to determine the complete pose history of the robot, $x_{1:t}$. This is often expressed as follows:
\begin{equation}
p(x_{1:t}, m | z_{1:t}, u_{1:t})
\end{equation}

Typically, \textit{online} SLAM is used to dynamically localise the robot, whilst \textit{full} SLAM is determine offline and is used to determine where the robot has been. It is not hard to see that the solution to the \textit{online} SLAM problem can be determined by solving the \textit{full} SLAM problem and integrating - the relationship between the two problems can be seen in equation ():
\begin{equation}
p(x_t, m | z_{1:t}, u_{1:t}) = \int_{x_{t-1}} \int_{x_{t-2}} \dots \int_{x_1} p(x_{1:t}, m | z_{1:t}, u_{1:t}) dx_1 dx_2 \dots dx_{t-1}
\end{equation}

NEED TO TALK ABOUT CORRESPONDENCES

\subsection{Grid Based FastSLAM}
FastSLAM was first proposed by XXXX. The central idea was an application of Rao-Blackwellized particle filters to estimate the joint posterior shown in equation (4) (reference to Murphy). The key assumption made in this paper was that if the robot's path, $x_{1:t}$, is known, then landmark locations are conditionally independent of pose (AND CORRESPONDENCES). This assumption allows us to factorise equation (4) as follows:
\begin{equation}
p(x_{1:t}, m | z_{1:t}, u_{1:t}) = p(x_{1:t} | z_{1:t}, u_{1:t}) \cdot p(m | x_{1:t}, z_{1:t})
\end{equation}

Factorisation effectively breaks the problem up into two smaller problems: estimation of the robot path $p(x_{1:t} | z_{1:t}, u_{1:t})$; and estimation of the robot map $p(m | x_{1:t}, z_{1:t})$. These smaller problems are known as the \textit{localisation} problem, and \textit{mapping} problem, respectively. Considering the problem in this light allows for an iterative algorithm for FastSLAM consisting of two main steps: the robot position is calculated; and then the map is updated based on that position.\\

Grid based FastSLAM uses the occupancy grid mapping algorithm, which is discussed in XXXX. The localisation problem can be solved using a particle filter, such as Monte Carlo Localisation (MCL), where each particle represents a potential trajectory of the robot. The mapping problem can be computed analytically, assuming $x_{1:t}$ and $z_{1:t}$ are known.\\

TALK ABOUT HOW THE FASTSLAM ALGORITHM ACTUALLY WORKS.\\

TALK ABOUT THE NEED FOR LANDMARKS IN VANILLA FASTSLAM, TALK ABOUT THE USE OF OCCUPANCY GRID MAPPING AND WHY IT IS OKAY TO USE THIS IN\\

TALK ABOUT TWO MAIN APPROACHES TO SOLVING SLAM PROBLEM (THEY ARE SPECIFICALLY NAMED - NEED TO CHECK THIS IN PAPER).\\

\subsubsection{Occupancy Grid Mapping}
A common technique for map representation is to decompose a continuous environment, $m$, into a discrete grid representation such that:
\begin{equation}
m = \sum_{i} m_i
\end{equation}

Each cell, $m_i$, is either occupied or unoccupied. This representation, first introduced by XXXX, is referred to as an occupancy grid map. SHOW FIGURE FOR OCCUPANCY GRID MAP

As previously mentioned, the mapping problem requires estimation of the posterior $p(m | x_{1:t}, z_{1:t})$. The main problem with estimating this posterior using a discrete grid cell representation is the high dimensionality. An example of this can be seen  by considering a map broken down into 500 discrete cells. If each cell is either occupied or unoccupied, then the total number of different maps that exist are $2^{500}$. Estimating $p(m | x_{1:t}, z_{1:t})$ requires determining the probability for each of the $2^{500}$ maps. This is computationally intractable for a system which needs to operate in real time. Instead of attempting this, occupancy grid algorithms estimate $p(m_i | x_{1:t}, z_{1:t})$ for each grid cell $m_i$. Considering the occupancy of each grid cell as independent from other grid cells, whilst not strictly true, is a convenient assumption allowing the expression expression of the posterior $p(m | x_{1:t}, z_{1:t})$ as a product of it's marginals:
\begin{equation}
p(m | x_{1:t}, z_{1:t}) = \prod_{i} p(m_i | x_{1:t}, z_{1:t})
\end{equation}

We note that $p(m_i | x_{1:t}, z_{1:t})$ in equation (XXXX) is estimating a fixed binary quantity from a sequence of sensor measurements. According to XXXX beliefs of this type are commonly implemented as \textit{log odds ratios}. We note that the \textit{odds} of a state is defined as the ratio of the probability of the binary event divided by the probability of its negate. Using Bayes' theorem, we express $p(m_i | x_{1:t}, z_{1:t})$ as follows:
\begin{equation}
p(m_i | x_{1:t}, z_{1:t}) = \frac{p(z_t | m_i, z_{1:t-1}, x_{1:t}) \cdot p(m_i | z_{1:t}, x_{1:t})}{p(z_t | z_{1:t-1}, x_{1:t})}
\end{equation}

Applying the Markov assumption for the first term in the numerator yields:
\begin{equation}
p(m_i | x_{1:t}, z_{1:t}) = \frac{p(z_t | m_i, x_{t}) \cdot p(m_i | z_{1:t}, x_{1:t})}{p(z_t | z_{1:t-1}, x_{1:t})}
\end{equation}

We note, applying Bayes' theorem, that:
\begin{equation}
p(z_t | m_i, x_t) = \frac{p(m_i | z_t, x_t) \cdot p(z_t | x_t)}{p(m_i | x_t)}
\end{equation}

Using equation (XXXX), we can re-express equation (XXXX) as:
\begin{equation}
p(m_i | x_{1:t}, z_{1:t}) = \frac{p(m_i | z_t, x_t) \cdot p(z_t | x_t) \cdot p(m_i | z_{1:t-1}, x_{1:t-1})}{p(m_i | x_t) \cdot p(z_t | z_{1:t-1}, x_{1:t})}
\end{equation}

A further application of the Markov assumption allows us to express equation (XXXX) as:
\begin{equation}
p(m_i | x_{1:t}, z_{1:t}) = \frac{p(m_i | z_t, x_t) \cdot p(z_t | x_t) \cdot p(m_i | z_{1:t-1}, x_{1:t-1})}{p(m_i) \cdot p(z_t | z_{1:t-1}, x_{1:t})}
\end{equation}

Similarly, we can follow the same process for the negate of $m_i$, $\neg m_i$. This yields the following expression:
\begin{equation}
p(\neg m_i | x_{1:t}, z_{1:t}) = \frac{p(\neg m_i | z_t, x_t) \cdot p(z_t | x_t) \cdot p(\neg m_i | z_{1:t-1}, x_{1:t-1})}{p( \neg m_i) \cdot p(z_t | z_{1:t-1}, x_{1:t})}
\end{equation}

Hence, after some manipulation, the \textit{odds} can be expressed as:
\begin{equation}
\frac{p(m_i | z_{1:t}, u_{1:t})}{p( \neg m_i | z_{1:t}, u_{1:t})} = \frac{p(m_i | z_t, x_t)}{1 - p(m_i | z_t, x_t)} \cdot \frac{p(m_i | z_{1:t-1}, x_{1:t-1})}{1 - p(m_i | z_{1:t-1}, x_{1:t-1})} \cdot \frac{1 - p(m_i)}{p(m_i)}
\end{equation}

Taking the logarithm of this yields the the \textit{log odds} calculation, $l_t$, for single grid cell:
\begin{equation}
l_t = \log \bigg( \frac{p(m_i | z_t, x_t)}{1 - p(m_i | z_t, x_t)} \bigg) + \log \bigg( \frac{p(m_i | z_{1:t-1}, x_{1:t-1})}{1 - p(m_i | z_{1:t-1}, x_{1:t-1})} \bigg) + \log \bigg( \frac{1 - p(m_i)}{p(m_i)} \bigg)
\end{equation}

We note that equation (XXXX) can be expressed recursively since the middle term is just $l_{t-1}$. Further, the inverted final term is simply the inital belief $l_0$ Hence, we get:
\begin{equation}
l_t = l_{t-1} + \log \bigg( \frac{p(m_i | z_t, x_t)}{1 - p(m_i | z_t, x_t)} \bigg) - l_0
\end{equation}

The final term in equation (XXXX) is just the initial belief for the grid cell, and the second to last term is referred to as the \textit{inverse sensor model}. The occupancy grid mapping algorithm takes the current pose $x_t$ and current sensor measurements $z_t$, along with the array of log odds ratios calculated in a previous iteration for each grid cell. This array is denoted as $\{l_{t-1,i}\}$. The algorithm simply loops through all of the grid cells which comprise an environmental map, updating the log odds ratio for each cell. The pseudo code for the occupancy grid algorithm can be seen in XXXX.




\subsubsection{Grid Based FastSLAM Algorithm}
The grid based FastSLAM algorithm uses a particle filter to 

\subsection{GraphSLAM}
GraphSLAM, in comparison to GBFS, takes a fundamentally different approach to solving the SLAM problem. The main idea behind GraphSLAM is to build up a graph that consists of robot poses, and map features. Edges between two corresponding pose nodes are referred to as motion constraints, and are derived from odometry sensor data. Edges between poses and map features are referred to as measurement constraints, and are derived from exteroceptive sensors. An example of a graph composed of pose nodes and map feature nodes can be seen in Figure XXXX. We see that the robot moves from pose $x_0$ to pose $x_1$, and so on. As the robot moves on to $x_3$, sensor detect map features $m_1$ and $m_2$. Odometric measurements are captured and used to create edges $e_1$, $e_2$, and $e_3$. Additionally, exteroceptive sensors capture the distance from the robot location to the map features resulting in dashed line edges $e_4$, $e_5$, $e_6$, and $e_7$. 
\begin{figure}[h]
\centering
\begin{tikzpicture}
% Draw the nodes used for the picture
\node[circle,fill=blue!20](a){$x_0$};
\node[circle,fill=blue!20,right of=a,node distance=2cm](b){$x_1$};
\node[circle,fill=blue!20,right of=b,node distance=2cm](c){$x_2$};
\node[circle,fill=blue!20,right of=c,node distance=2cm](d){$x_3$};
\node(e) at ($(a)!0.5!(b)$){};
\node(f) at ($(c)!0.5!(d)$){};
\node[circle,fill=green!20,below of=e,node distance=2cm](g){$m_1$};
\node[circle,fill=green!20,below of=f,node distance=2cm](h){$m_2$};

% Draw the edges between the nodes
\draw (a) -- node[above]{$e_1$} (b);
\draw (b) -- node[above]{$e_2$} (c);
\draw (c) -- node[above]{$e_3$} (d);
\draw[dashed] (a) -- node[left]{$e_4$} (g);
\draw[dashed] (b) -- node[right]{$e_5$} (g);
\draw[dashed] (c) -- node[left]{$e_6$} (h);
\draw[dashed] (d) -- node[right]{$e_7$} (h);
\end{tikzpicture}
\caption{text}
\end{figure}


\section{Scene and robot configuration}

explains how the gazebo world was created by providing an overview of the layout of items in his/her customized Gazebo world. Student also describes the robot's parameters, sensor features, and reasoning on the package structure.

\section{Results}
Results - The student should include the images for mapping process, final map (2D/3D) for both Gazebo worlds.


\section{Discussion}
Discussion - The student explains how the procedure went and methodologies to improve it. The student should compare and contrast the performance of RTAB Mapping in different worlds.


\section{Future Work}


\bibliography{my_bib}
\bibliographystyle{ieeetr}

\end{document}